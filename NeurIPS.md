# Oral Paper
- **LLM Evaluators Recognize and Favor Their Own Generations** [[Paper](https://arxiv.org/abs/2404.13076)]

# Spotlight Paper
- **Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences** [[Paper](https://arxiv.org/abs/2407.09499)]

- **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models** [[Paper](https://arxiv.org/abs/2406.04271)]

- **Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare** [[Paper](https://arxiv.org/abs/2405.19298)]
# Poster Paper

- **Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale** [[Paper](https://arxiv.org/abs/2409.15637)]

- **Detecting Bugs with Substantial Monetary Consequences by LLM and Rule-based Reasoning** [[Paper](https://openreview.net/pdf?id=hB5NkiET32)]

- **A Critical Evaluation of AI Feedback for Aligning Large Language Models** [[Paper](https://arxiv.org/pdf/2402.12366)] 

- **Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing** [[Paper](https://arxiv.org/abs/2404.12253)]

- **Verified Code Transpilation with LLMs** [[Paper](https://arxiv.org/abs/2406.03003)]

- **JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models** [[Paper](https://arxiv.org/abs/2405.14365)]

- **ReST-MCTS\*: LLM Self-Training via Process Reward Guided Tree Search** [[Paper](https://arxiv.org/abs/2406.03816)]

- **AutoSurvey: Large Language Models Can Automatically Write Surveys** [[Paper](https://arxiv.org/abs/2406.10252)]

- **Self-Discover: Large Language Models Self-Compose Reasoning Structures** [[Paper](https://arxiv.org/abs/2402.03620)]

- **Self-Retrieval: End-to-End Information Retrieval with One Large Language Model** [[Paper](https://arxiv.org/abs/2403.00801)]

- **LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems** [[Paper](https://openreview.net/pdf?id=VpuOuZOVhP)]

- **Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning** [[Paper](https://openreview.net/pdf?id=jXsxGt80sv)]

- **RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold** [[Paper](https://arxiv.org/abs/2406.14532)]

- **INDICT: Code Generation with Internal Dialogues of Critiques for Both Security and Helpfulness** [[Paper](https://openreview.net/pdf?id=jCMYIUwprx)]

- **SelectIT: Selective Instruction Tuning for Large Language Models via Uncertainty-Aware Self-Reflection** [[Paper](https://arxiv.org/abs/2402.16705)]

- **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph** [[Paper](https://arxiv.org/abs/2406.17271)]

- **CriticEval: Evaluating Large Language Model as Critic** [[Paper](https://arxiv.org/abs/2402.13764)]

- **AlphaMath Almost Zero: Process Supervision without Process** [[Paper](https://arxiv.org/abs/2405.03553)]

- **Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision** [[Paper](https://arxiv.org/abs/2403.09472)]

- **On scalable oversight with weak LLMs judging strong LLMs** [[Paper](https://arxiv.org/abs/2407.04622)]

- **ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation** [[Paper](https://arxiv.org/abs/2405.14125)]

- **StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving** [[Paper](https://arxiv.org/abs/2311.08803)]

- **Weak-eval-Strong: Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles** [[Paper](https://arxiv.org/abs/2410.06733)]

- **Reflective Multi-Agent Collaboration based on Large Language Models** [[Paper](https://openreview.net/pdf?id=wWiAR5mqXq)]

- **A Theoretical Understanding of Self-Correction through In-context Alignment** [[Paper](https://arxiv.org/abs/2405.18634)]

- **Discovering Preference Optimization Algorithms with and for Large Language Models** [[Paper](https://arxiv.org/abs/2406.08414)]

- **MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures** [[Paper](https://arxiv.org/abs/2406.06565)]

- **Iterative Reasoning Preference Optimization** [[Paper](https://arxiv.org/pdf/2404.19733)]

- **Dual-Personalizing Adapter for Federated Foundation Models** [[Paper](https://arxiv.org/abs/2403.19211)]

- **Training LLMs to Better Self-Debug and Explain Code** [[Paper](https://arxiv.org/abs/2405.18649)]

- **SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data** [[Paper](https://arxiv.org/abs/2403.06952)]

- **Multi-LLM Debate: Framework, Principals, and Interventions** [[Paper](https://openreview.net/pdf?id=sy7eSEXdPC)]

- **Rule Based Rewards for Language Model Safety** [[Paper](https://openreview.net/pdf?id=QVtwpT5Dmg)]

- **Recursive Introspection: Teaching Language Model Agents How to Self-Improve** [[Paper](https://arxiv.org/pdf/2407.18219)]

- **SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain** [[Paper](https://arxiv.org/abs/2407.19584)]

- **RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold** [[Paper](https://arxiv.org/pdf/2406.14532)]